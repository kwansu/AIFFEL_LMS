{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 멋진 작사가 만들기\n",
    "\n",
    "RNN을 이용해서 여러 가사를 학습시킨 모델로 새로운 가사를 만들어보자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. 모듈 import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import glob\r\n",
    "import os, re \r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 데이터 다운로드\n",
    "\n",
    "\n",
    "미리 준비된 데이터를 사용한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 데이터 읽어오기\n",
    "glob로 모든 파일을 읽어서 하나의 리스트에 넣는다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "raw_corpus = []\r\n",
    "txt_list = glob.glob(r'C:\\Users\\kwansu\\Desktop\\AIFFEL_LMS\\E_04_\\data\\*')\r\n",
    "\r\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\r\n",
    "for txt_file in txt_list:\r\n",
    "    with open(txt_file, \"r\", encoding='UTF8') as f:\r\n",
    "        raw = f.read().splitlines()\r\n",
    "        raw_corpus.extend(raw)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터가 잘 로드 됐는지 확인해보자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Examples:\n",
      " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 데이터 정제\n",
    "\n",
    "### 정규화를 통한 전처리\n",
    "\n",
    "정규화를 통해 필요없는 특수문자등을 제거하자.\n",
    "\n",
    "그리고 너무 긴 문장은 노래가사에 어울리지 않을 수 있고,  \n",
    "나머지 데이터의 0 padding이 너무 많아 지므로 15개이상의 토큰을 가질 경우 제거하자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 입력된 문장을\r\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\r\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\r\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\r\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\r\n",
    "#     5. 다시 양쪽 공백을 지웁니다\r\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\r\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\r\n",
    "def preprocess_sentence(sentence):\r\n",
    "    sentence = sentence.lower().strip() # 1\r\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\r\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\r\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\r\n",
    "    sentence = sentence.strip() # 5\r\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\r\n",
    "    return sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "corpus = []\r\n",
    "words = set()\r\n",
    "\r\n",
    "for sentence in raw_corpus:\r\n",
    "    if len(sentence.strip()) == 0: # 문자가 아예 없거나 공백으로 채워져있으면 제외\r\n",
    "        continue\r\n",
    "    \r\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\r\n",
    "    \r\n",
    "    token = preprocessed_sentence.split()\r\n",
    "    words.update(token)\r\n",
    "    if len(token) > 15: # 문자가 15개를 넘으면 제외한다.\r\n",
    "        continue\r\n",
    "    \r\n",
    "    corpus.append(preprocessed_sentence)\r\n",
    "        \r\n",
    "#corpus[0:10] # 전처리를 거친 데이터 10개만 출력\r\n",
    "print(f\"사용된 총 단어 개수 {len(words)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용된 총 단어 개수 27621\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 평가 데이터셋 분리\n",
    "\n",
    "전처리된 데이터를 통해 학습 데이터셋과 테스트 데이터셋을 만들어보자.\n",
    "\n",
    "### 데이터 토큰화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def tokenize(corpus, num_words):\r\n",
    "    # num_words 만큼 단어를 기억할 수 있는 tokenizer를 생성\r\n",
    "    # num_words 단어에 포함되지 못한 단어는 '<unk>' 대체\r\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, filters=' ', oov_token=\"<unk>\")\r\n",
    "    \r\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\r\n",
    "    tokenizer.fit_on_texts(corpus)\r\n",
    "    \r\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\r\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \r\n",
    "    \r\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\r\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\r\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \r\n",
    "    \r\n",
    "    return tensor, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "현재 모든 문장에서 사용된 총 단어 개수는 27621개이다.  \n",
    "거의 사용되지 않는 단어를 제외하고, 많이 사용하는 순서대로  \n",
    "절반쯤인 13000개의 단어를 저장하였다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tensor, tokenizer = tokenize(corpus, 13000)\r\n",
    "\r\n",
    "src_input = tensor[:, :-1]  \r\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\r\n",
    "tgt_input = tensor[:, 1:]\r\n",
    "\r\n",
    "for idx in tokenizer.index_word:\r\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\r\n",
    "\r\n",
    "    if idx >= 10:\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "가장 많이 사용된 글자는 pad와 start, end를 제외하면 i , the you 순이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 분리\n",
    "\n",
    "sklearn의 train_test_split을 사용해서 학습데이터와 테스트데이터로 분리하자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=7)\r\n",
    "\r\n",
    "print(\"Source Train:\", enc_train.shape)\r\n",
    "print(\"Target Train:\", dec_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source Train: (124960, 14)\n",
      "Target Train: (124960, 14)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset만들기\n",
    "문자가 토큰화되어 숫자로 바뀐 tensor를 이용하여 학습시킬 데이터 셋을 만들자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "BUFFER_SIZE = len(src_input)\r\n",
    "BATCH_SIZE = 256\r\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\r\n",
    "\r\n",
    " # tokenizer가 구축한 단어사전 내 13000개와, 여기 포함되지 않은 0:<pad>를 포함하여 13001개\r\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \r\n",
    "\r\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\r\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\r\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n",
    "\r\n",
    "# 검증 데이터셋 만들기\r\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\r\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 인공지능 만들기\n",
    "이제 준비된 데이터셋을 모델을 만들어 학습시켜보자.\n",
    "\n",
    "### 모델 구성"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class TextGenerator(tf.keras.Model):\r\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\r\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\r\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\r\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\r\n",
    "        \r\n",
    "    def call(self, x):\r\n",
    "        out = self.embedding(x)\r\n",
    "        out = self.rnn_1(out)\r\n",
    "        out = self.rnn_2(out)\r\n",
    "        out = self.linear(out)\r\n",
    "        \r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 하이퍼 파라미터 설정\n",
    "데이터의 양이 많아진 만큼 임베딩 사이즈와 히든레이어를 좀 더 키웠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "embedding_size = 512\r\n",
    "hidden_size = 2048\r\n",
    "epochs=20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#print(f\"gpu를 사용 : {tf.test.is_gpu_available()}\")\r\n",
    "\r\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\r\n",
    "\r\n",
    "optimizer = tf.keras.optimizers.Adam()\r\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\r\n",
    "\r\n",
    "lyricist.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\r\n",
    "hist = lyricist.fit(train_dataset, epochs=20, validation_data=val_dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TextGenerator.call of <__main__.TextGenerator object at 0x00000255959999C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method TextGenerator.call of <__main__.TextGenerator object at 0x00000255959999C8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "Train for 488 steps, validate for 123 steps\n",
      "Epoch 1/20\n",
      "488/488 [==============================] - 327s 670ms/step - loss: 3.3833 - accuracy: 0.4926\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kwansu\\AppData\\Local\\Temp/ipykernel_908/849086307.py\", line 9, in <module>\n",
      "    hist = lyricist.fit(train_dataset, epochs=20, validation_data=val_dataset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 395, in fit\n",
      "    total_epochs=1)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 174, in run_one_epoch\n",
      "    aggregator.aggregate(batch_outs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\", line 136, in aggregate\n",
      "    self.results[0] += batch_outs[0]\n",
      "ValueError: operands could not be broadcast together with shapes (256,14) (9,14) (256,14) \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kwansu\\AppData\\Local\\Temp/ipykernel_908/849086307.py\", line 9, in <module>\n",
      "    hist = lyricist.fit(train_dataset, epochs=20, validation_data=val_dataset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 395, in fit\n",
      "    total_epochs=1)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 174, in run_one_epoch\n",
      "    aggregator.aggregate(batch_outs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\", line 136, in aggregate\n",
      "    self.results[0] += batch_outs[0]\n",
      "ValueError: operands could not be broadcast together with shapes (256,14) (9,14) (256,14) \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kwansu\\AppData\\Local\\Temp/ipykernel_908/849086307.py\", line 9, in <module>\n",
      "    hist = lyricist.fit(train_dataset, epochs=20, validation_data=val_dataset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 395, in fit\n",
      "    total_epochs=1)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 174, in run_one_epoch\n",
      "    aggregator.aggregate(batch_outs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\", line 136, in aggregate\n",
      "    self.results[0] += batch_outs[0]\n",
      "ValueError: operands could not be broadcast together with shapes (256,14) (9,14) (256,14) \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3170, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3380, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\kwansu\\anaconda3\\envs\\tf_opencv\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_model_path = os.getenv('HOME')+'/aiffel/lyricist/model/'\r\n",
    "filename = f'lyricist_{embedding_size}_{hidden_size}_epochs.h5'\r\n",
    "\r\n",
    "lyricist.save_weights(save_model_path + filename)\r\n",
    "print(f\"모델을 저장하였습니다. 위치 : {save_model_path}{filename}\")\r\n",
    "\r\n",
    "plt.plot(hsit.history['loss'], 'y', label='train loss')\r\n",
    "#loss_ax.plot(hsit.history['val_loss'], 'r', label='val loss')\r\n",
    "#acc_ax.plot(hsit.history['accuracy'], 'b', label='train acc')\r\n",
    "#acc_ax.plot(hsit.history['val_accuracy'], 'g', label='val acc')\r\n",
    "    \r\n",
    "    \r\n",
    "plt.legend(loc='upper left')\r\n",
    "plt.legend(loc='lower left')\r\n",
    "    \r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\r\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\r\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\r\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\r\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\r\n",
    "\r\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\r\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\r\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\r\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\r\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\r\n",
    "    while True:\r\n",
    "        # 1\r\n",
    "        predict = model(test_tensor) \r\n",
    "        # 2\r\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \r\n",
    "        # 3 \r\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\r\n",
    "        # 4\r\n",
    "        if predict_word.numpy()[0] == end_token: break\r\n",
    "        if test_tensor.shape[1] >= max_len: break\r\n",
    "\r\n",
    "    generated = \"\"\r\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \r\n",
    "    for word_index in test_tensor[0].numpy():\r\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\r\n",
    "\r\n",
    "    return generated"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<start> i love you , i m not gonna crack <end> '"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf_opencv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "f8652a7c3fd8775712bbb521170f52e43e97145ae9447698c06921aeccc31900"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}