{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitted-heritage",
   "metadata": {},
   "source": [
    "# 멋진 작사가 만들기\n",
    "\n",
    "RNN을 이용해서 여러 가사를 학습시킨 모델로 새로운 가사를 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-draft",
   "metadata": {},
   "source": [
    "## 0. 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "damaged-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-plymouth",
   "metadata": {},
   "source": [
    "## 1. 데이터 다운로드\n",
    "\n",
    "\n",
    "미리 준비된 데이터를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-consistency",
   "metadata": {},
   "source": [
    "## 2. 데이터 읽어오기\n",
    "glob로 모든 파일을 읽어서 하나의 리스트에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rotary-sleeve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/Exploration/E04_MakeLyricist/data/*'\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in glob.glob(txt_file_path):\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(f\"데이터 크기: {len(raw_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-intranet",
   "metadata": {},
   "source": [
    "데이터가 잘 로드 됐는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "improving-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      " ['The first words that come out', 'And I can see this song will be about you', \"I can't believe that I can breathe without you\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-tactics",
   "metadata": {},
   "source": [
    "## 3. 데이터 정제\n",
    "\n",
    "### 정규화를 통한 전처리\n",
    "\n",
    "정규화를 통해 필요없는 특수문자등을 제거하자.\n",
    "\n",
    "그리고 너무 긴 문장은 노래가사에 어울리지 않을 수 있고,  \n",
    "나머지 데이터의 0 padding이 너무 많아 지므로 15개이상의 토큰을 가질 경우 제거하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intermediate-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용된 총 단어 개수 27621\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "words = set()\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence.strip()) == 0: # 문자가 아예 없거나 공백으로 채워져있으면 제외\n",
    "        continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    token = preprocessed_sentence.split()\n",
    "    words.update(token)\n",
    "    if len(token) > 15: # 문자가 15개를 넘으면 제외한다.\n",
    "        continue\n",
    "    \n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "#corpus[0:10] # 전처리를 거친 데이터 10개만 출력\n",
    "print(f\"사용된 총 단어 개수 {len(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-leather",
   "metadata": {},
   "source": [
    "## 4. 평가 데이터셋 분리\n",
    "\n",
    "전처리된 데이터를 통해 학습 데이터셋과 테스트 데이터셋을 만들어보자.\n",
    "\n",
    "### 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "widespread-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus, num_words):\n",
    "    # num_words 만큼 단어를 기억할 수 있는 tokenizer를 생성\n",
    "    # num_words 단어에 포함되지 못한 단어는 '<unk>' 대체\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, filters=' ', oov_token=\"<unk>\")\n",
    "    \n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-smart",
   "metadata": {},
   "source": [
    "현재 모든 문장에서 사용된 총 단어 개수는 27621개이다.  \n",
    "거의 사용되지 않는 단어를 제외하고, 많이 사용하는 순서대로  \n",
    "절반쯤인 13000개의 단어를 저장하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "remarkable-prisoner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "tensor, tokenizer = tokenize(corpus, 13000) # 단어장의 크기는 13000\n",
    "\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]\n",
    "\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-mirror",
   "metadata": {},
   "source": [
    "가장 많이 사용된 글자는 pad와 start, end를 제외하면 i , the you 순이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-oregon",
   "metadata": {},
   "source": [
    "### 데이터 분리\n",
    "\n",
    "sklearn의 train_test_split을 사용해서 학습데이터와 테스트데이터로 분리하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stopped-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124960, 14)\n",
      "Target Train: (124960, 14)\n"
     ]
    }
   ],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=7)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-obligation",
   "metadata": {},
   "source": [
    "### Dataset만들기\n",
    "문자가 토큰화되어 숫자로 바뀐 tensor를 이용하여 학습시킬 데이터 셋을 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "formed-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 13000개와, 여기 포함되지 않은 0:<pad>를 포함하여 13001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# 테스트 데이터셋 만들기\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-banks",
   "metadata": {},
   "source": [
    "## 5. 인공지능 만들기\n",
    "이제 준비된 데이터셋을 모델을 만들어 학습시켜보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-thermal",
   "metadata": {},
   "source": [
    "### 모델 구성\n",
    "기존의 LSTM의 2층 짜리 레이어는 오차가 잘 줄지 않아, Bidirectional을 사용하여  \n",
    "양방향으로 학습하는 모델을 구성하였다.\n",
    "\n",
    "CuDNN 커널을 사용하기 위해 활성화 함수는 'tanh'를 사용하였다.  \n",
    "CuDNN 커널을 사용하기 위한 사양은 다음 공식사이트에서 확인가능하다.  \n",
    "https://www.tensorflow.org/guide/keras/rnn?hl=ko#%EC%84%B1%EB%8A%A5_%EC%B5%9C%EC%A0%81%ED%99%94_%EB%B0%8F_cudnn_%EC%BB%A4%EB%84%90\n",
    "\n",
    "그리고 batchnormal를 사용하여 overfiting을 어느정도 방지하고, dropout을 대체하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mexican-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        forward_layer = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        backward_layer = tf.keras.layers.LSTM(hidden_size, activation='tanh',\n",
    "                                             return_sequences=True, go_backwards=True)\n",
    "        self.rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "        self.batchnormal = tf.keras.layers.BatchNormalization()\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn(out)\n",
    "        out = self.batchnormal(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-rover",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 설정\n",
    "데이터의 양이 많아진 만큼 임베딩 사이즈와 히든레이어를 좀 더 키웠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accurate-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-comparison",
   "metadata": {},
   "source": [
    "학습 과정에서 loss값 외에도 accuracy를 확인하려고 추가해 보았는데,  \n",
    "학습 속도가 너무 느려져서 그냥 빼버렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passing-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu를 사용 : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"gpu를 사용 : {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sunset-onion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6656512   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional multiple                  41959424  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  16384     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  53265097  \n",
      "=================================================================\n",
      "Total params: 101,897,417\n",
      "Trainable params: 101,889,225\n",
      "Non-trainable params: 8,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tgt_sample in train_dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "lyricist(src_sample)\n",
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-burke",
   "metadata": {},
   "source": [
    "### 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ultimate-infrared",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 605s 1s/step - loss: 2.0547 - val_loss: 0.6879\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 603s 1s/step - loss: 0.0170 - val_loss: 0.0318\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 603s 1s/step - loss: 0.0023 - val_loss: 0.0270\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 602s 1s/step - loss: 0.0010 - val_loss: 0.0277\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 603s 1s/step - loss: 8.4181e-04 - val_loss: 0.0277\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 675s 1s/step - loss: 0.0015 - val_loss: 0.0315\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 1551s 3s/step - loss: 0.0028 - val_loss: 0.0320\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 1547s 3s/step - loss: 0.0037 - val_loss: 0.0266\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 1545s 3s/step - loss: 0.0022 - val_loss: 0.0203\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 1542s 3s/step - loss: 0.0011 - val_loss: 0.0163\n"
     ]
    }
   ],
   "source": [
    "hist = lyricist.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-delay",
   "metadata": {},
   "source": [
    "### 학습결과 확인\n",
    "학습한 모델을 저장하여 나중에 확인 가능하게 만들었다.\n",
    "\n",
    "그리고 학습동안의 loss를 그래프로 그려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델을 저장하였습니다. 위치 : /aiffel/aiffel/lyricist/model/lyricist_512_2048_10(1).h5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiNElEQVR4nO3df3xcdZ3v8ddn8juTpO22BaUtpK1dsL9oIa2J9YKsqBRWYL1i5RbBVWHdByCs3tWq4EV2H/chF+6u8FgUuSxedHFZRLjyuIK4KhdQ+dHQpoX+klJbmvKjaZeW5vck87l/nEkzmUzSJM3kZOa8n4/HPObMOWfOfDrNzHvO+Z7v95i7IyIi0RULuwAREQmXgkBEJOIUBCIiEacgEBGJOAWBiEjEFYddwGjNmDHDa2trwy5DRCSvvPjiiwfcfWa2ZXkXBLW1tTQ2NoZdhohIXjGzPUMt06EhEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCIuMkFw+PDv2LXra2jYbRGRgSITBEeObOC1175Nd/ebYZciIjKpRCYI4vHFALS1vRxyJSIik0sEg+ClkCsREZlcIhMEpaUzKSk5UXsEIiIZIhMEAFVVS7RHICKSIVJBEI8vpq1tC+7JsEsREZk0IhYES0gmO+js/GPYpYiITBoRC4Kgwbi1VYeHRET6RCoIKisXAjqFVEQkXU6DwMzOM7MdZrbTzNZlWX6ymT1pZhvNbLOZnZ/LeoqLqygvn6cGYxGRNDkLAjMrAu4EVgMLgUvNbGHGajcAD7r7cuBTwHdzVU+foMFYewQiIn1yuUewEtjp7rvcvRt4ALgoYx0HalLTU4DXc1gPEDQYt7fvIJnsyvVLiYjkhVwGwSxgb9rj5tS8dDcBl5lZM/AYcG22DZnZVWbWaGaNLS0tx1VU0GDcS3v7juPajohIoQi7sfhS4H+7+2zgfOBHZjaoJne/293r3L1u5syZx/WCVVVLAA01ISLSJ5dBsA+Yk/Z4dmpeus8BDwK4+7NAOTAjhzVRUfGnmJWonUBEJCWXQbAeWGBmc82slKAx+NGMdV4DPgRgZu8lCILjO/ZzDLFYCZWVp6kvgYhISs6CwN17gGuAJ4BtBGcHbTGzm83swtRqXwauNLNNwL8Cn/EJuHKMzhwSEelXnMuNu/tjBI3A6fO+mTa9FViVyxqyiceXsH//v9LT8w7FxTXHfoKISAELu7E4FP3XJtgSciUiIuGLeBDo8JCISCSDoLz8FIqKqnQKqYgIEQ0CsxiVlYu0RyAiQkSDAPqvVjYBJymJiExqkQ2CeHwxicQBEon9YZciIhKqCAdBMNSEOpaJSNRFOAh05pCICEQ4CEpLT6Ck5ASdOSQikRfZIAANNSEiApEPgiW0tW3BPRl2KSIioYl4ECwmmWyjs3N32KWIiIQm8kEAajAWkWiLeBAsAnS1MhGJtkgHQXFxNeXltdojEJFIi3QQQNBgrE5lIhJlCoL4Yjo6dpBMdoddiohIKBQE8SW499DeviPsUkREQqEg0JlDIhJx0QmC9evhW98aNLuy8lTMinXmkIhEVnSC4Nln4aaboLl5wOxYrJSKilO1RyAikRWdIGhoCO6ffXbQor6L1IiIRFF0guD006G8PGsQxOOL6ezcTU/PkRAKExEJV3SCoLQUzjxzyCAAaG/fOtFViYiELjpBAMHhoQ0boKtrwGxdrUxEoix6QdDdDRs3DphdXl5LLBZXg7GIRFK0gqC+PrjPODxkFiMeX6QGYxGJpGgFwUknwcknD9lOoD0CEYmiaAUBBIeHsgbBEhKJ/XR37w+hKBGR8EQzCJqbB3Us01ATIhJV0QwCgOeeGzC7qio4c0jtBCISNdELgmXLoKxs0OGhkpITKCmZoT0CEYmc6AXBEB3LzEwXqRGRSIpeEEBweOjFF7N0LFtMe/sW3JMhFSYiMvGiGwTd3dDUNGB2PL6E3t5WOjv3hFOXiEgIohsEMOjwkM4cEpEoimYQDNGxLB5fBCgIRCRaohkEEAw3kREExcU1lJWdolNIRSRSchoEZnaeme0ws51mtm6IdT5pZlvNbIuZ/TiX9QzQ0AB798K+fQNma6gJEYmanAWBmRUBdwKrgYXApWa2MGOdBcDXgFXuvgi4Plf1DDJMx7L29u0kk4kJK0VEJEy53CNYCex0913u3g08AFyUsc6VwJ3u/jaAu0/cQD/Ll2ftWBaPL8Y9QUfHHyasFBGRMOUyCGYBe9MeN6fmpftT4E/N7Hdm9pyZnZdtQ2Z2lZk1mlljS0vL+FQ3RMcyXaRGRKIm7MbiYmAB8EHgUuB/mdnUzJXc/W53r3P3upkzZ47fq9fXBx3LuruPzqqsPBUoUjuBiERGLoNgHzAn7fHs1Lx0zcCj7p5w9z8CfyAIhonR0BD0Lk67YlksVkZl5ak6c0hEIiOXQbAeWGBmc82sFPgU8GjGOv+HYG8AM5tBcKhoVw5rGmiIBmOdOSQiUZKzIHD3HuAa4AlgG/Cgu28xs5vN7MLUak8AB81sK/Ak8LfufjBXNQ0yaxbMmZO1naCzcxc9Pa0TVoqISFiKc7lxd38MeCxj3jfTph34UuoWjixXLOsbaqK9fSs1NSvDqEpEZMKE3Vgcvvp6eO01eP31o7M05pCIRImCIMsAdBUV84jFKtRgLCKRoCBYvjzoU5DWYGwWIx5fpD0CEYkEBUFZ2ZAdy9SpTESiQEEAweGhxsYBHcvi8cUkEm/R3T1OPZlFRCYpBQEEDcZdXQOuWNY31IQOD4lIoVMQQNYGY505JCJRoSAAmD07uKU1GJeWvovi4uk6c0hECp6CoE9GxzIz01ATIhIJCoI+9fWwZw+88cbRWVVVS2hre5mgA7SISGFSEPQZop2gt/cIXV2vhVSUiEjuKQj6nHHGoI5lajAWkShQEPQpKwvCIMuZQ+pYJiKFTEGQLqNjWXHxFMrK5miPQEQKmoIgXX09dHbCpk1HZ8XjS3QKqYgUNAVBuiEajNvbt5NMJkIqSkQktxQE6ebMCa5aNqDBeAnu3XR0vBJiYSIiuaMgyJTRsUxnDolIoVMQZGpogN274c03AaisPA0oUjuBiBQsBUGm+vrgPrVXUFRUTmXlAu0RiEjBUhBkOuMMKCnJODyki9SISOFSEGQqLw/CIKOHcWfnLnp720IsTEQkNxQE2fR1LEsEp4wGDcZOW9vWcOsSEckBBUE2DQ3Q0XG0Y5muViYihUxBkE1Gg3FFxTxisQoFgYgUJAVBNnPmwEknHQ0CsyIqKxfqFFIRKUgKgmzMgsNDGQ3G2iMQkUKkIBhKQwP88Y/w1ltAcLWy7u43SCQOhlyYiMj4GlEQmNl1ZlZjgX82sw1m9pFcFxeqjAHoNNSEiBSqke4RfNbd3wE+AkwDPg18O2dVTQYZHcv6zhxSxzIRKTQjDQJL3Z8P/Mjdt6TNK0zl5bB8+dEgKC19N8XF07RHICIFZ6RB8KKZ/ZIgCJ4ws2ogmbuyJom0jmVmpovUiEhBGmkQfA5YB6xw93agBPjLnFU1WfR1LNu8Geg/c8jdQy5MRGT8jDQIGoAd7n7IzC4DbgAO566sSSJLg3Fv7zt0de0NsSgRkfE10iD4HtBuZqcDXwZeBX6Ys6omizlz4N3vHtRgrHYCESkkIw2CHg+Oh1wE/JO73wlU566sSaKvY9nRIFgEKAhEpLCMNAiOmNnXCE4b/bmZxQjaCQpfWseykpJplJXNVoOxiBSUkQbBGqCLoD/Bm8Bs4NZjPcnMzjOzHWa208zWDbPefzYzN7O6EdYzcfraCVLDTWioCREpNCMKgtSX//3AFDP7c6DT3YdtIzCzIuBOYDWwELjUzBZmWa8auA54fpS1T4wsHcva2raRTPaEXJiIyPgY6RATnwReAC4BPgk8b2afOMbTVgI73X2Xu3cDDxC0MWT6O+AWoHPEVU+kigpYtmzAmUPuXXR07Ay3LhGRcTLSQ0PfIOhDcIW7X07wJX/jMZ4zC0g/z7I5Ne8oMzsDmOPuPx9uQ2Z2lZk1mlljS0vLCEseRw0NsH49JBJpZw6pnUBECsNIgyDm7vvTHh8cxXOzSjU4/wPB6ajDcve73b3O3etmzpx5PC87Nn0dy156icrK04CY2glEpGCM9Mv8F2b2hJl9xsw+A/wceOwYz9kHzEl7PDs1r081sBj4f2a2G6gHHp3UDcbPPktRUQUVFQu0RyAiBWOkjcV/C9wNLE3d7nb3rx7jaeuBBWY218xKgU8Bj6Zt87C7z3D3WnevBZ4DLnT3xjH8O3Lr5JPhXe8a0E6gPQIRKRTFI13R3X8K/HQU6/eY2TXAE0ARcK+7bzGzm4FGd390+C1MIoM6li3mwIGH6e1tp6ioMuTiRESOz7BBYGZHgGwjrBng7l4z3PPd/TEyDiG5+zeHWPeDw1YatoYGeOQR2L+fqqolgNPevo3q6jPDrkxE5LgMe2jI3avdvSbLrfpYIVBw0jqW9V2tTBepEZFCoGsWj9SZZ0JxMTz7LBUV78GsTO0EIlIQFAQjldaxzKyIeHyhgkBECoKCYDT6Opb19OhqZSJSMBQEo9HQAO3t8NJLxOOL6e5+nUTiP8KuSkTkuCgIRiOtY5kuUiMihUJBMBqnnHK0Y1nfmUMKAhHJdwqC0TCD+np49lnKymZRXDxV7QQikvcUBKPV0ACvvoq1tGioCREpCAqC0eprJ3j+eeLxxbS2vkRwOWcRkfykIBiturqjHcvi8SX09h6mq2vfsZ8nIjJJKQhGK61jWX+DsdoJRCR/KQjGor4eXniBeNlpgM4cEpH8piAYi1THspLt+ygtPUlBICJ5TUEwFgNGItVQEyKS3xQEY1FbCyeeeLSdoK1tK+69YVclIjImCoKxSLtiWVXVEty76OjYGXZVIiJjoiAYq/p62LmTqo5ZgBqMRSR/KQjGKtVOULHpEGC6WpmI5C0FwVilOpYVrd9IRcV7tEcgInlLQTBWlZVw+ulpDcbaIxCR/KQgOB4NDamOZYvo6NhJb29H2BWJiIyaguB41NdDWxtT9tYASdrbt4VdkYjIqCkIjkeqwTi+uRXQmUMikp8UBMdj7lw44QRKN+zCrExBICJ5SUFwPFIdy+y554nH36sGYxHJSwqC49XQAK+8Qk23TiEVkfykIDhe9fUATN1RRVdXM4nE2yEXJCIyOgqC41VXB0VFVL0cnDra1rYl5IJEREZHQXC84nE4/XTKNuwFdLUyEck/CoLx0NBArHEzRVSrnUBE8o6CYDzU12Otrcx4c572CEQk7ygIxkOqY9m0HTW0tb2Mu4dckIjIyCkIxsO8eTBzJtUvd9HT8zbd3a+HXZGIyIgpCMZDqmNZedMbgIaaEJH8oiAYLw0NFO3cS/FhdJEaEckrCoLxkupYNv2VadojEJG8ktMgMLPzzGyHme00s3VZln/JzLaa2WYz+7WZnZLLenJqxQooKuJPdkxVEIhIXslZEJhZEXAnsBpYCFxqZgszVtsI1Ln7UuAh4H/kqp6ci8dh6VKqt/bS3r4F996wKxIRGZFc7hGsBHa6+y537wYeAC5KX8Hdn3T39tTD54DZOawn9xoaKN/0FslEJx0du8KuRkRkRHIZBLOAvWmPm1PzhvI54PEc1pN7DQ3E2rqI79ZQEyKSPyZFY7GZXQbUAbcOsfwqM2s0s8aWlpaJLW40Ug3GNVt0CqmI5I9cBsE+YE7a49mpeQOY2bnAN4AL3b0r24bc/W53r3P3upkzZ+ak2HExfz7MmMGf7KjWHoGI5I1cBsF6YIGZzTWzUuBTwKPpK5jZcuD7BCGwP4e1TIxUx7Kara49AhHJGzkLAnfvAa4BngC2AQ+6+xYzu9nMLkytditQBfzEzJrM7NEhNpc/Ghoo291K95t/oLe3M+xqRESOqTiXG3f3x4DHMuZ9M2363Fy+fihSA9DVbE3Sfs52qquXhVuPiMgxTIrG4oJSV4fHYtRs1ZlDIpIfFATjraoKli5hyhZTO4GI5AUFQQ5Yw/up2WG0vaM9AhGZ/BQEudDQQFFbEt+yIexKRESOSUGQC6kG4/KNb9HTczjkYkREhqcgyIX580lOr0k1GKudQEQmNwVBLpjh71vBFA01ISJ5QEGQI7H3n0PlXmhvXh92KSIiw1IQ5Ii9//3B/QvPh1yJiMjwFAS5smIFHjNKGnfi7mFXIyIyJAVBrlRVkTjtJKpe7qS7+82wqxERGZKCIIf8fWdQsw3a3mkKuxQRkSEpCHKo6AMfobgdujf9JuxSRESGlNPRRydKIpGgubmZzs5JNuxz3Vnw+OP0xst4e9u2sKsZVnl5ObNnz6akpCTsUkRkghVEEDQ3N1NdXU1tbS1mFnY5/dzx3gQ9VUWULHhv2NUMyd05ePAgzc3NzJ07N+xyRGSCFcShoc7OTqZPnz65QgDAjGRlKbGOnkl95pCZMX369Mm3RyUiE6IgggCYfCHQJ15BUTckE+1hVzKsSfv+iUjOFUwQTFpVNQB466Fw6xARGYKCYBwcOnSI7373u1mXxaqm4QCtrVmXn3/++Rw6dGjEr3XTTTdx2223jb5IEZEhKAjGwXBB0IuRLDOsLfvx98cee4ypU6fmsDoRkeEVxFlD6V555XpaW5vGdZtVVctYsOA7Qy5ft24dr776KsuWLePDH/4wF1xwATfeeCPTpk1j+/btbH38IT7xuS+y98gROjs7ue6667jqqqsAqK2tpbGxkdbWVlavXs0HPvABfv/73zNr1ix+9rOfUVFRMeTrNjU18YUvfIH29nbmz5/Pvffey7Rp07jjjju46667KC4uZuHChTzwwAM89dRTXHfddUDQHvD0009TXV09ru+TiOQn7RGMg29/+9vMnz+fpqYmbr31VgA2bNjA7bffzh/+8Ac8XsG9N95I4zPP0NjYyB133MHBgwcHbeeVV17h6quvZsuWLUydOpWf/vSnw77u5Zdfzi233MLmzZtZsmQJ3/rWt47Ws3HjRjZv3sxdd90FwG233cadd95JU1MTzzzzzLABIyLRUnB7BMP9cp9IK1eu7D8nv6qGO/7t33jki9dCcQl79+7llVdeYfr06QOeM3fuXJYtWwbAmWeeye7du4fc/uHDhzl06BBnn302AFdccQWXXHIJAEuXLmXt2rVcfPHFXHzxxQCsWrWKL33pS6xdu5aPf/zjzJ49e1z/vSKSv7RHkCPxePzo9NPPN/Gr9S/wuwd/zKZNm1i+fHnWc/bLysqOThcVFdHT0zOm1/75z3/O1VdfzYYNG1ixYgU9PT2sW7eOe+65h46ODlatWsX27dvHtG0RKTwKgnFQXV3NkSNHhlx+5Eg7U6dWU5mE7du389xzzx33a06ZMoVp06bxzDPPAPCjH/2Is88+m2Qyyd69eznnnHO45ZZbOHz4MK2trbz66qssWbKEr371q6xYsUJBICJHFdyhoTBMnz6dVatWsXjxYlavXs0FF1wwYPnq1efzve/8TxZd+BecunQp9fX14/K6991339HG4nnz5vGDH/yA3t5eLrvsMg4fPoy788UvfpGpU6dy44038uSTTxKLxVi0aBGrV68elxpEJP/ZZB76IJu6ujpvbGwcMG/btm28972TdywfgK4DOyjbfQQWLIApU8IuJ6t8eB9FZGzM7EV3r8u2TIeGJkq8Gge8dehDSCIiYVAQTJBYcSXJMgWBiEw+CoIJUlRUQW85WHsH5NnhOBEpbAqCCWJWSrLCsN4kaLhnEZlEFAQTxMzweHnwYIgB6EREwqDTRyeQlcdJFnVgbW3YjBmgawDI8XLPzS0Wg8pKKC8PpqWgKQgmUKyogmQ5FB84QNXChbT+9rfBh8wsuI/FqFqxgtYNG44+Tl826sfZps3GN4Ayv0CSydFNT6b2ku5u6Orqv0+fzjYvF8sTicHvz1C3iVJeDhUVQTBUVmafHo95paX6cRQSBcEEisUq6JoJVjM9+IOfObP/Q59MBre+L+re3uBLIX1Z+hfE8RUy+FeeO7S0QEPD6L7MpV9REZSVBbfS0oH36dM1NUMvLykZGNhh3ZJJ6OiA9vb++/TpvvtDh7Kvl0yO/v2LxbIHRjzef6uqGvg48zbc8pKScf8vLxSFFwTXXw9NTeO7zWXL4DvfGXLxunXrmDNnDldffTUQXDymqqqKL3zhC1x00UW8/fbbJBIJbr75Js499xR6ayqDD9ucOYM3Zgannoq785WvfIXHH38cM+OGG25gzZo1vPHGG6xZs4Z33nmHnkSC791xB++vr+dzf/VXNG7YgJnx2bVr+Zu//uvBIZP5OPN129vhiiv6vwyy7Ukca3o066bfwuae/Us727xsy0tLgyCQ4L1MJLIHx0jndXRAW1sw3dYGBw/Ca68F021tQTvbaE+6KCkZe5iUl/f/3w91S//7KCvLq7+HwguCEKxZs4brr7/+aBA8+OCDPPHEE5SXl/PII49QU1PDgQMHqK+vZ+PGn9Db23HMbT788MM0NTWxadMmDhw4wIoVKzjrrLP48Y9/zEc/+lG+8Y1v0NvbS3t7O03bt7Pvrbd4eetWILhQDmO52E1bG9x+++ifJ5LOLPhSLC0d29/hSPX29gdF+q21dfC84Zb1hUz6svE4sy99D3GosBjt8nPPhaVLj7+2DIUXBMP8cs+V5cuXs3//fl5//XVaWlqYNm0ac+bMIZFI8PWvf52nn36aWCzGvn37aGlpY+ZMA5zOzj2YFWNWkroP/juSyW6eeeYZLr30UoqKijjxxBM5++yzWb9+PStWrOCzn/0siUSCiy++mGXLljFv3jx27drFtddeywUXXMBHPvKRCX8PRCZcURFUVwe38ZYeMn17H5ntO0PdjrVO5vLW1uHXSST667rrrvwLAjM7D7gdKALucfdvZywvA34InAkcBNa4++5c1pQrl1xyCQ899BBvvvkma9asAeD++++npaWFF198kZKSEmpra+ntrSYWKwOcROJtIHOo6SRtbZtJJPbT2bmH1taXMCump+cdurreYuXK5fz7v/+EX/ziSa644tNcf/21XH755Wzc+CK//OWvuOuuu3jwwQe59957J/otECkcuQyZ0Uom+4Mhbaj68ZSzIDCzIuBO4MNAM7DezB51961pq30OeNvd32NmnwJuAdbkqqZcWrNmDVdeeSUHDhzgqaeeAoKLx5xwwgmUlJTw5JNPsmfPHkpKphCP1wIxqquX4e649xy9QYyyslM466wPcc89P+Tyyy/jwIGD/O536/n7v7+OV1/dzKxZM7jssrNoa3uT9euf5Jxz5lFSUsxHP1rLySdfxuc/fwPt7dsH7GlkuwXdSPqPz7sn6ek5glnf/BhmdnS9vmmbDMf0C1QwCGQS9960v4vejPseYPC84dfLvrxvevB6velVZZ0eOGDlsadHu37AMCtK/b0Wpf52s9/ncnn/Z6Dvs5F9OiefjVgsaKMoLx//bafkco9gJbDT3XcBmNkDwEVAehBcBNyUmn4I+CczM8+3IVGBRYsWceTIEWbNmsW73/1uANauXcvHPvYxlixZQl1dHaeddtqg55kZZiVA/xkNpaUz+eQnP0tj43bq6/8CM+PWW/+R+fP/jPvuu481a75KSUkx8XglP/jB9zhw4BBXXnktyWQv4Nx881cASCY70r4Qjq2r6wC//e3iEf6LMz8MfQGRLUAyP0TZ1k3fbrZ70tYbbv1s6w1eP/treurLqu/LuG/acU8ene5fL5nxnJGuN3Dbg58XRdn+PyB47/KNMVxYHM/0vHn/nRNPXDv+FefqO9fMPgGc5+6fTz3+NPA+d78mbZ2XU+s0px6/mlrnQMa2rgKuAjj55JPP3LNnz4DX0vDJwwv2OtJ/8fXgniDzQ7Zjx26mTHmGgV9WfV9i/V9UfdP98zLXHfy8oddNr8EH3Gf/BTl43vDrZftFOtT6gz+Agz+QmQE2uvUGbztzj8sy9twyf61m+8U6XuulLx8qoIeeHsn6Y/nF7J6+h5S5B5P9fvyXD/77D2P6Xe+6gmnTzhn1e5h674cchjovGovd/W7gbgiuRxByOXkn2Oso5lj/3cXF/8HJJ//XiSlKZITMYqkAVT+AXMll3/F9QPqJ8rNT87KuY8E31RSCRmMREZkguQyC9cACM5trZqXAp4BHM9Z5FLgiNf0J4DdjbR/Iw2aFSUXvn0h05SwIPDjQdg3wBLANeNDdt5jZzWZ2YWq1fwamm9lO4EvAurG8Vnl5OQcPHtSX2Ri5OwcPHqQ8h2cliMjkVRDXLE4kEjQ3N9Opcf7HrLy8nNmzZ1Oi8VhEClLeNxYfS0lJCXPnzg27DBGRvKSBxkVEIk5BICIScQoCEZGIy7vGYjNrAfYcc8XsZgAHjrlWdOj9GEjvRz+9FwMVwvtxirvPzLYg74LgeJhZ41Ct5lGk92MgvR/99F4MVOjvhw4NiYhEnIJARCTiohYEd4ddwCSj92MgvR/99F4MVNDvR6TaCEREZLCo7RGIiEgGBYGISMRFJgjM7Dwz22FmO81sTKOcFgIzm2NmT5rZVjPbYmbXhV3TZGBmRWa20cz+b9i1hM3MpprZQ2a23cy2mVlD2DWFxcz+JvU5ednM/tXMCnKI3kgEgQVXn74TWA0sBC41s4XhVhWaHuDL7r4QqAeujvB7ke46guHSBW4HfuHupwGnE9H3xcxmAV8E6tx9MVBEcF2VghOJIABWAjvdfZe7dwMPABeFXFMo3P0Nd9+Qmj5C8CGfFW5V4TKz2cAFwD1h1xI2M5sCnEVwrRDcvdvdD4VaVLiKgYrUFRQrgddDricnohIEs4C9aY+bifiXH4CZ1QLLgedDLiVs3wG+AiRDrmMymAu0AD9IHSq7x8ziYRcVBnffB9wGvAa8ARx291+GW1VuRCUIJIOZVQE/Ba5393fCricsZvbnwH53fzHsWiaJYuAM4HvuvhxoY4xXDsx3ZjaN4MjBXOAkIG5ml4VbVW5EJQj2AXPSHs9OzYskMyshCIH73f3hsOsJ2SrgQjPbTXDI8M/M7F/CLSlUzUCzu/ftJT5EEAxRdC7wR3dvcfcE8DDw/pBryomoBMF6YIGZzTWzUoIGn0dDrikUZmYEx3+3ufs/hF1P2Nz9a+4+291rCf4ufuPuBfmrbyTc/U1gr5mdmpr1IWBriCWF6TWg3swqU5+bD1GgDecFcanKY3H3HjO7BniCoOX/XnffEnJZYVkFfBp4ycyaUvO+7u6PhVeSTDLXAvenfjTtAv4y5HpC4e7Pm9lDwAaCs+02UqBDTWiICRGRiIvKoSERERmCgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhEJpCZfVAjnMpkoyAQEYk4BYFIFmZ2mZm9YGZNZvb91PUKWs3sH1Pj0//azGam1l1mZs+Z2WYzeyQ1Rg1m9h4z+5WZbTKzDWY2P7X5qrTx/u9P9VoVCY2CQCSDmb0XWAOscvdlQC+wFogDje6+CHgK+G+pp/wQ+Kq7LwVeSpt/P3Cnu59OMEbNG6n5y4HrCa6NMY+gt7dIaCIxxITIKH0IOBNYn/qxXgHsJxim+t9S6/wL8HBq/P6p7v5Uav59wE/MrBqY5e6PALh7J0Bqey+4e3PqcRNQC/w25/8qkSEoCEQGM+A+d//agJlmN2asN9bxWbrSpnvR51BCpkNDIoP9GviEmZ0AYGZ/YmanEHxePpFa578Av3X3w8DbZvafUvM/DTyVuvpbs5ldnNpGmZlVTuQ/QmSk9EtEJIO7bzWzG4BfmlkMSABXE1ykZWVq2X6CdgSAK4C7Ul/06aN1fhr4vpndnNrGJRP4zxAZMY0+KjJCZtbq7lVh1yEy3nRoSEQk4rRHICIScdojEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiPv/0+i7RoBbRpcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_save_path(forder_path, filename):\n",
    "    file_path = f'{forder_path}/{filename}'\n",
    "    uniq = 1\n",
    "    while os.path.exists(file_path + '.h5'):\n",
    "        file_path = f'{forder_path}/{filename}({uniq})'\n",
    "        uniq += 1\n",
    "    return file_path\n",
    "\n",
    "forder_path = os.getenv('HOME')+'/aiffel/lyricist/model'\n",
    "filename = f'lyricist_{embedding_size}_{hidden_size}_{epochs}'\n",
    "save_file_path = create_save_path(forder_path, filename)\n",
    "\n",
    "# rnn등의 한방향 sequence가 아닌 모델에는 model.save가 안되서 weight로 저장\n",
    "lyricist.save_weights(save_file_path +'.h5')\n",
    "print(f\"모델을 저장하였습니다. 위치 : {save_file_path}.h5\")\n",
    "    \n",
    "plt.plot(hist.history['loss'], 'y', label='train loss')\n",
    "plt.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(save_file_path + '.png')  # 나중에 확인가능하게 학습 그래프를 이미지로 같은 이름으로 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-launch",
   "metadata": {},
   "source": [
    "## 6. 가사 생성하기\n",
    "학습한 모델로 부터 노래 가사를 생성해보자.\n",
    "\n",
    "다음은 모델로 부터 시작 단어를 받아서 문장을 완성키는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "crude-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-economy",
   "metadata": {},
   "source": [
    "i love 다음으로 어떤 가사가 생성될 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "naval-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love to steal the tear like an speaking turn up <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-issue",
   "metadata": {},
   "source": [
    "'i love to steal the tear like an speaking turn up' 라는 말이 나왔는데,  \n",
    "솔직히 영어를 잘 못해서 제대로 나온건지 알 수가없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-witness",
   "metadata": {},
   "source": [
    "## 7. 회고\n",
    "\n",
    "RNN을 통해 문장을 생성하는 기본적인 내용을 해보았다.  \n",
    "아직 토큰화된 문자열을 임베딩하는 과정이나 RNN이 되는 원리를  \n",
    "정확하게 파악하지 못 한것 같다.\n",
    "\n",
    "다만 토큰화된 단어들을 추상적인 과정으로 표현된다는 것에서  \n",
    "여러 의미로 자연어 처리에 대한 전반적인 과정을 어느정도 이해한 것 같기도하다.\n",
    "\n",
    "나중에라도 자연어 처리에 대한 전반적인 공부를 해야할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
