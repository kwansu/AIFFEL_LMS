{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\r\n",
    "import keras_ocr\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from functools import reduce\r\n",
    "# 상대경로를 사용했다. 환경에 맞춰 경로를 변경해야한다.\r\n",
    "from popeval.popEval import process, make_pair, _divide"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking for C:\\Users\\kwansu\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\kwansu\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "image_files = sorted(glob.glob('data/img_*.png'))\r\n",
    "\r\n",
    "images = [keras_ocr.tools.read(path) for path in image_files]\r\n",
    "prediction_groups = [pipeline.recognize([path]) for path in image_files]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def create_converted_format_file(load_path, save_path):\r\n",
    "    ''' 수작업으로 작성한 좌표정보를 포맷에 맞게 변형하여 저장한다.\r\n",
    "    텍스트에서 줄마다 하나의 검출된 영역과 그 영역에서의 단어를 나타낸다.\r\n",
    "    직사각형 박스는 (x   y   w   h   word)로 기록하였다.\r\n",
    "    사다리꼴은 (@   x1   y1   ...  x4   y4   word)이며 @로 시작한다.\r\n",
    "    단어 사이의 띄어쓰기가 있을수 있어서 구분은 탭(\\t)으로만 하였다.\r\n",
    "    추가로 keras-ocr에서 모두 소문자로만 나와서 문자를 소문자로 변경\r\n",
    "    하였는데, 필요하다면 특수문자나 띄어쓰기도 처리하면 좋을 듯하다.'''\r\n",
    "\r\n",
    "    with open(load_path, \"r\") as f:\r\n",
    "        lines = f.readlines()\r\n",
    "\r\n",
    "    with open(save_path, \"w\") as f:\r\n",
    "        for line in lines:\r\n",
    "            words = line.split('\\t')\r\n",
    "            if words[0] == '@':     # 사다리꼴 검출\r\n",
    "                line = ' '.join(words[1:9]) + f' ##::{words[-1].lower()}'\r\n",
    "            else:                   # 직사각형 검출\r\n",
    "                x, y, w, h = map(int, words[:4])\r\n",
    "                line = f\"{x} {y} {x+w} {y} {x+w} {y+h} {x} {y+h}##::{words[-1].lower()}\"\r\n",
    "            f.writelines(line)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for i in range(1, len(image_files)+1):\r\n",
    "    load_path = f'data/coord_{i:03d}.txt'       # 노가다로 만든 텍스트 경로\r\n",
    "    save_path = f'data/GT_{i:03d}.txt'          # 포맷에 맞게 저장할 경로\r\n",
    "    create_converted_format_file(load_path, save_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for i, pred in enumerate(prediction_groups, start=1):\r\n",
    "    save_path = f'data/Pred_{i:03d}.txt'\r\n",
    "    with open(save_path, \"w\") as f:\r\n",
    "        for img_info in pred:\r\n",
    "            for line in img_info:\r\n",
    "                for i in range(4):\r\n",
    "                    f.write(f'{int(line[1][i][0])} {int(line[1][i][1])} ')\r\n",
    "                f.write(f'##::{line[0]}\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def evaluate(gt_files, pred_files, dontcare_text='###'):\r\n",
    "    removed_gt_char_count = 0\r\n",
    "    precision_list = []\r\n",
    "    recall_list = []\r\n",
    "\r\n",
    "    total_removed_gt_char_count = 0\r\n",
    "    total_pred_char_count = 0\r\n",
    "    total_gt_chars_count = 0\r\n",
    "\r\n",
    "    # 기존 멀티프로세스로 되어있던것을 변경하였다. 느리다면 기존 코드를 참고해서 변경할것.\r\n",
    "    for result in map(process, gt_files, pred_files, [dontcare_text]*len(pred_files)):\r\n",
    "        try:\r\n",
    "            precision, recall, removed_gt_char_count, pred_char_count, gt_char_count = result\r\n",
    "            total_removed_gt_char_count += removed_gt_char_count\r\n",
    "            total_pred_char_count += pred_char_count\r\n",
    "            total_gt_chars_count += gt_char_count\r\n",
    "            precision_list.append(precision)\r\n",
    "            recall_list.append(recall)\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "\r\n",
    "    precision_for_char = _divide(\r\n",
    "        float(total_removed_gt_char_count), float(total_pred_char_count))\r\n",
    "    recall_for_char = _divide(\r\n",
    "        float(total_removed_gt_char_count), float(total_gt_chars_count))\r\n",
    "    #precision_avr = _divide(reduce(lambda x, y: x + y, precision_list, 0), len(precision_list))\r\n",
    "    #recall_avr = _divide(reduce(lambda x, y: x + y, recall_list, 0), len(recall_list))\r\n",
    "    perf = _divide(2*(precision_for_char*recall_for_char),\r\n",
    "                   (precision_for_char + recall_for_char))\r\n",
    "\r\n",
    "    print(' num | precision |  recall  |')\r\n",
    "    for i, (precision, recall) in enumerate(zip(precision_list, recall_list), start=1):\r\n",
    "        print(f' {i:03d} | {precision:f}  | {recall:f} |')\r\n",
    "    print(\"======================\")\r\n",
    "    return precision_for_char, recall_for_char, perf\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "GT_files = sorted(glob.glob('data/GT_*.txt'))\r\n",
    "D_files = sorted(glob.glob('data/Pred_*.txt'))\r\n",
    "\r\n",
    "if len(GT_files) != len(D_files):\r\n",
    "    print(\"Caution: GT_files' len(%d) and D_files' len(%d) are different.\"%(len(GT_files), len(D_files)))\r\n",
    "    GT_files, D_files = make_pair(GT_files, D_files)\r\n",
    "    print(\"We will evaluate on %d files\"%(len(GT_files)))\r\n",
    "\r\n",
    "pr, re, pref = evaluate(GT_files, D_files)\r\n",
    "print(\"precision, recall, H:\")\r\n",
    "print(\"%0.1f, %0.1f, %0.1f\"%(100.*pr, 100.*re, 100.*pref))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " num | precision |  recall  |\n",
      " 001 | 0.989130  | 0.968085 |\n",
      " 002 | 0.957447  | 0.900000 |\n",
      "======================\n",
      "precision, recall, H:\n",
      "97.8, 94.4, 96.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('ocr2': conda)"
  },
  "interpreter": {
   "hash": "eb836e79313413e1cf41ff75ed4e8861e42b30e70a1841b675f619fd89fa66b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}